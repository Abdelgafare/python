{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b617597",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36ebc03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### import the data \n",
    "df=pd.read_csv('C:\\\\Users\\\\pc\\\\Desktop\\\\Heart disese data\\\\heart_disease_data.csv')\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b76835fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age       sex        cp  trestbps      chol       fbs  \\\n",
      "age       1.000000 -0.098447 -0.068653  0.279351  0.213678  0.121308   \n",
      "sex      -0.098447  1.000000 -0.049353 -0.056769 -0.197912  0.045032   \n",
      "cp       -0.068653 -0.049353  1.000000  0.047608 -0.076904  0.094444   \n",
      "trestbps  0.279351 -0.056769  0.047608  1.000000  0.123174  0.177531   \n",
      "chol      0.213678 -0.197912 -0.076904  0.123174  1.000000  0.013294   \n",
      "fbs       0.121308  0.045032  0.094444  0.177531  0.013294  1.000000   \n",
      "restecg  -0.116211 -0.058196  0.044421 -0.114103 -0.151040 -0.084189   \n",
      "thalach  -0.398522 -0.044020  0.295762 -0.046698 -0.009940 -0.008567   \n",
      "exang     0.096801  0.141664 -0.394280  0.067616  0.067023  0.025665   \n",
      "oldpeak   0.210013  0.096093 -0.149230  0.193216  0.053952  0.005747   \n",
      "slope    -0.168814 -0.030711  0.119717 -0.121475 -0.004038 -0.059894   \n",
      "ca        0.276326  0.118261 -0.181053  0.101389  0.070511  0.137979   \n",
      "thal      0.068001  0.210041 -0.161736  0.062210  0.098803 -0.032019   \n",
      "target   -0.225439 -0.280937  0.433798 -0.144931 -0.085239 -0.028046   \n",
      "\n",
      "           restecg   thalach     exang   oldpeak     slope        ca  \\\n",
      "age      -0.116211 -0.398522  0.096801  0.210013 -0.168814  0.276326   \n",
      "sex      -0.058196 -0.044020  0.141664  0.096093 -0.030711  0.118261   \n",
      "cp        0.044421  0.295762 -0.394280 -0.149230  0.119717 -0.181053   \n",
      "trestbps -0.114103 -0.046698  0.067616  0.193216 -0.121475  0.101389   \n",
      "chol     -0.151040 -0.009940  0.067023  0.053952 -0.004038  0.070511   \n",
      "fbs      -0.084189 -0.008567  0.025665  0.005747 -0.059894  0.137979   \n",
      "restecg   1.000000  0.044123 -0.070733 -0.058770  0.093045 -0.072042   \n",
      "thalach   0.044123  1.000000 -0.378812 -0.344187  0.386784 -0.213177   \n",
      "exang    -0.070733 -0.378812  1.000000  0.288223 -0.257748  0.115739   \n",
      "oldpeak  -0.058770 -0.344187  0.288223  1.000000 -0.577537  0.222682   \n",
      "slope     0.093045  0.386784 -0.257748 -0.577537  1.000000 -0.080155   \n",
      "ca       -0.072042 -0.213177  0.115739  0.222682 -0.080155  1.000000   \n",
      "thal     -0.011981 -0.096439  0.206754  0.210244 -0.104764  0.151832   \n",
      "target    0.137230  0.421741 -0.436757 -0.430696  0.345877 -0.391724   \n",
      "\n",
      "              thal    target  \n",
      "age       0.068001 -0.225439  \n",
      "sex       0.210041 -0.280937  \n",
      "cp       -0.161736  0.433798  \n",
      "trestbps  0.062210 -0.144931  \n",
      "chol      0.098803 -0.085239  \n",
      "fbs      -0.032019 -0.028046  \n",
      "restecg  -0.011981  0.137230  \n",
      "thalach  -0.096439  0.421741  \n",
      "exang     0.206754 -0.436757  \n",
      "oldpeak   0.210244 -0.430696  \n",
      "slope    -0.104764  0.345877  \n",
      "ca        0.151832 -0.391724  \n",
      "thal      1.000000 -0.344029  \n",
      "target   -0.344029  1.000000  \n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "\n",
    "# Display the correlation matrix as a table\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c230d84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "## look that we dont need to change variables to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acfdf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926ca684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "### no null variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b1759ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### i think we will jump into identifying the variables\n",
    "x=df.drop(columns='target')\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d4c5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c12049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit  Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "075ffb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted No</th>\n",
       "      <th>Predicted Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual No</th>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Yes</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted No  Predicted Yes\n",
       "Actual No             33             11\n",
       "Actual Yes             4             43"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "predict=model.predict(x_test)\n",
    "# confusion matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test,predict),columns=['Predicted No','Predicted Yes'],index=['Actual No','Actual Yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb7b5e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81        44\n",
      "           1       0.80      0.91      0.85        47\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.84      0.83      0.83        91\n",
      "weighted avg       0.84      0.84      0.83        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "136363d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy =  0.8351648351648352\n"
     ]
    }
   ],
   "source": [
    "### model accuracy \n",
    "\n",
    "from sklearn import metrics\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "model_prediction = model.predict(x_test)\n",
    "print('Logistic Regression accuracy = ', metrics.accuracy_score(lr_prediction,y_test))### or model.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0179469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547854785478548"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### new  note this accuracy not for the all model its for the training set only if we want for the model we will go to the one\n",
    "##### above and the code above is based on takink ((acc of training set+acc of test set )/2)\n",
    "model.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8cef1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.331239\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                  212\n",
      "Model:                          Logit   Df Residuals:                      198\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 19 Feb 2024   Pseudo R-squ.:                  0.5177\n",
      "Time:                        05:33:52   Log-Likelihood:                -70.223\n",
      "converged:                       True   LL-Null:                       -145.59\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.472e-25\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.1225      3.479      0.898      0.369      -3.696       9.941\n",
      "age            0.0128      0.028      0.451      0.652      -0.043       0.068\n",
      "sex           -2.0772      0.576     -3.605      0.000      -3.206      -0.948\n",
      "cp             0.8422      0.232      3.634      0.000       0.388       1.296\n",
      "trestbps      -0.0124      0.014     -0.909      0.363      -0.039       0.014\n",
      "chol          -0.0065      0.004     -1.489      0.136      -0.015       0.002\n",
      "fbs           -0.7764      0.639     -1.215      0.224      -2.029       0.476\n",
      "restecg        0.2416      0.439      0.550      0.582      -0.619       1.103\n",
      "thalach        0.0240      0.014      1.773      0.076      -0.003       0.051\n",
      "exang         -0.9484      0.495     -1.916      0.055      -1.919       0.022\n",
      "oldpeak       -0.7721      0.286     -2.696      0.007      -1.333      -0.211\n",
      "slope          0.2352      0.450      0.523      0.601      -0.647       1.117\n",
      "ca            -0.8634      0.249     -3.461      0.001      -1.352      -0.375\n",
      "thal          -0.8842      0.347     -2.546      0.011      -1.565      -0.204\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools as tools\n",
    "\n",
    "# add constant to training data\n",
    "x_train_const = tools.add_constant(x_train)\n",
    "# Train the logistic regression with the training data\n",
    "log_reg = sm.Logit(y_train, x_train_const).fit()\n",
    "print(log_reg.summary())\n",
    "### note that The estimated coefficient for each predictor. This represents the change \n",
    "###in the log-odds of the target variable for a one-unit change in the predictor, holding all other predictors constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b55285d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "The Person does not have a Heart Disease\n"
     ]
    }
   ],
   "source": [
    "### perdictive system \n",
    "input_data = (62,0,0,140,268,0,0,160,0,3.6,0,2,2)\n",
    "\n",
    "# change the input data to a numpy array\n",
    "input_data_as_numpy_array= np.asarray(input_data)\n",
    "\n",
    "# reshape the numpy array as we are predicting for only on instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]== 0):\n",
    "  print('The Person does not have a Heart Disease')\n",
    "else:\n",
    "  print('The Person has Heart Disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b484bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.348904\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.348911\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.348982\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.351612\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.355900\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.361116\n",
      "         Iterations 7\n",
      "Selected features: ['sex', 'cp', 'trestbps', 'thalach', 'exang', 'oldpeak', 'ca', 'thal']\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                  303\n",
      "Model:                          Logit   Df Residuals:                      294\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 19 Feb 2024   Pseudo R-squ.:                  0.4760\n",
      "Time:                        06:13:22   Log-Likelihood:                -109.42\n",
      "converged:                       True   LL-Null:                       -208.82\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.143e-38\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.7935      1.884      1.483      0.138      -0.899       6.486\n",
      "sex           -1.5054      0.420     -3.581      0.000      -2.329      -0.681\n",
      "cp             0.8291      0.177      4.672      0.000       0.481       1.177\n",
      "trestbps      -0.0204      0.010     -2.090      0.037      -0.040      -0.001\n",
      "thalach        0.0260      0.009      2.859      0.004       0.008       0.044\n",
      "exang         -0.9890      0.397     -2.489      0.013      -1.768      -0.210\n",
      "oldpeak       -0.7027      0.186     -3.780      0.000      -1.067      -0.338\n",
      "ca            -0.7029      0.176     -3.988      0.000      -1.048      -0.357\n",
      "thal          -0.9048      0.280     -3.229      0.001      -1.454      -0.356\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "###backward step wise because the full model didnt seem so good for me bec Log-Likelihood:\n",
    "\n",
    "def backward_stepwise_selection(x, y):\n",
    "    selected_features = list(x.columns)\n",
    "    while True:\n",
    "        x_selected = x[selected_features]\n",
    "        model = sm.Logit(y, sm.add_constant(x_selected)).fit()\n",
    "        pvalues = model.pvalues[1:]  # Exclude the constant term\n",
    "        max_pvalue = pvalues.max()\n",
    "        if max_pvalue > 0.05:  # Stopping criterion (adjust as needed)\n",
    "            remove_feature = pvalues.idxmax()\n",
    "            selected_features.remove(remove_feature)\n",
    "        else:\n",
    "            break\n",
    "    return selected_features, model\n",
    "\n",
    "selected_features, final_model = backward_stepwise_selection(x, y)\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(final_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5f5ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['exang', 'ca', 'oldpeak', 'cp', 'thal', 'sex', 'thalach', 'trestbps']\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                  303\n",
      "Model:                          Logit   Df Residuals:                      293\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 19 Feb 2024   Pseudo R-squ.:                  0.4834\n",
      "Time:                        06:14:18   Log-Likelihood:                -107.88\n",
      "converged:                       True   LL-Null:                       -208.82\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.343e-38\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4234      1.916      1.265      0.206      -1.332       6.179\n",
      "exang         -0.9472      0.401     -2.364      0.018      -1.732      -0.162\n",
      "ca            -0.7553      0.184     -4.115      0.000      -1.115      -0.396\n",
      "oldpeak       -0.5313      0.207     -2.562      0.010      -0.938      -0.125\n",
      "cp             0.8541      0.180      4.739      0.000       0.501       1.207\n",
      "thal          -0.9160      0.279     -3.278      0.001      -1.464      -0.368\n",
      "sex           -1.5888      0.433     -3.667      0.000      -2.438      -0.740\n",
      "thalach        0.0228      0.009      2.451      0.014       0.005       0.041\n",
      "trestbps      -0.0210      0.010     -2.131      0.033      -0.040      -0.002\n",
      "slope          0.6045      0.341      1.770      0.077      -0.065       1.274\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "### forward \n",
    "def forward_stepwise_selection(x, y):\n",
    "    selected_features = []\n",
    "    remaining_features = list(x.columns)\n",
    "    while True:\n",
    "        best_pvalue = 1.0\n",
    "        for feature in remaining_features:\n",
    "            x_selected = x[selected_features + [feature]]\n",
    "            model = sm.Logit(y, sm.add_constant(x_selected)).fit(disp=0)\n",
    "            pvalue = model.pvalues[feature]\n",
    "            if pvalue < best_pvalue:\n",
    "                best_pvalue = pvalue\n",
    "                best_feature = feature\n",
    "                best_model = model\n",
    "        if best_pvalue < 0.05:  # Stopping criterion (adjust as needed)\n",
    "            selected_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "        else:\n",
    "            break\n",
    "    return selected_features, best_model\n",
    "\n",
    "selected_features, final_model = forward_stepwise_selection(x, y)\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### in conclusion the best model is the full model and we dont need to remove any varaibles "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
